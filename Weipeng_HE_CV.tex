%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Plasmati Graduate CV
% LaTeX Template
% Version 1.0 (24/3/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Alessandro Plasmati (alessandro.plasmati@gmail.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
% Important note:
% This template needs to be compiled with XeLaTeX.
% The main document font is called Fontin and can be downloaded for free
% from here: http://www.exljbris.com/fontin.html
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[a4paper,9pt]{extarticle} % Default font size and paper size

\usepackage{fontspec} % For loading fonts
%\defaultfontfeatures{Mapping=tex-text}
\setmainfont{Lora}
\setsansfont{Muli}
\setmonofont{Muli}
%\setmonofont[Scale=0.9]{Roboto Mono}

\usepackage{parskip}

\usepackage[usenames,dvipsnames]{xcolor} % Required for specifying custom colors

\usepackage{fullpage}

\usepackage{soul}

\usepackage[bookmarks]{hyperref}
\definecolor{linkcolour}{rgb}{0,0.2,0.6} % Link color
\hypersetup{colorlinks,breaklinks,urlcolor=linkcolour,linkcolor=linkcolour} % Set link colors throughout the document

\usepackage{titlesec} % Used to customize the \section command
\titleformat{\section}{\LARGE\bfseries\scshape\sffamily\raggedright}{}{0em}{}[\titlerule] % Text formatting of sections
\titlespacing{\section}{0pt}{8mm}{3mm} % Spacing around sections

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\rhead{Weipeng He, Page \thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\setlength{\headheight}{15pt}
\setlength{\headsep}{10pt}

\usepackage{enumitem}
\setitemize{itemsep=-.4em,leftmargin=2em}
%\renewcommand\labelitemi{-}

\hyphenation{Tsinghua}
\newcommand{\ind}{\hspace*{1em}}

\setlength{\parskip}{12pt}

\begin{document}
\thispagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	NAME AND CONTACT INFORMATION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
  {\Huge\bfseries\sffamily WEIPENG HE}

  Seattle, WA 98109 $\bullet$
  \href{mailto:heweipeng@gmail.com}{\texttt{heweipeng@gmail.com}} $\bullet$
  \texttt{+1 (206) 209-7280} $\bullet$
  \url{www.linkedin.com/in/hwp0}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	Key Words
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
  {\LARGE\bfseries\sffamily Senior Research Scientist} \\[4pt]
  Audio and Speech Processing $\bullet$ Machine Learning $\bullet$ On-device Model Optimization $\bullet$ Speech Enhancement \\
  Microphone Array Processing $\bullet$ Keyword Spotting $\bullet$ Sound Source Localization $\bullet$ Sound Separation
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Experiences
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Experience}

\textbf{Meta}  \hfill Seattle, WA \\
\textit{Senior Research Scientist} \hfill September 2021 --- Present%
\vspace{-.4\parskip}

Conducted research and deployment of speech and audio signal processing techniques to wearable devices.
\vspace{-.9\parskip}
\begin{itemize}[nosep]
  \item Deployed a lightweight speech enhancement model to a DSP on smart glasses, reducing computational cost by 30\% through quantization and computational graph optimization techniques.
  \item Developed multi-channel end-to-end wake word detection models for smart glasses, enhancing noise robustness. Optimized model efficiency, resulting in a 30-minute increase in device battery life.
  \item Implemented real-time barge-in detection on smart glasses, achieving less than 5\% false rejection and false acceptance rates, enabling seamless natural conversation with large language models.
  \item Led an exploratory research project to design and prototype an audio "magic eraser" model capable of isolating individual sounds from mixtures based on sound classes, enabling selective suppression or enhancement of specific sounds in videos.
  \item Mentored two interns in their research projects on multi-channel sound separation and audio-visual noise suppression, providing guidance on experimental design, data analysis, and manuscript preparation, culminating in peer-reviewed publications and submissions.
\end{itemize}

\textbf{Idiap Research Institute}  \hfill Martigny, Switzerland \\
% \textit{Postdoctoral Researcher} \hfill November 2020 --- August 2021 \\
% \textit{Research Assistant} \hfill June 2016 --- October 2020%
\textit{Research Assistant} \hfill June 2016 --- August 2021%
\vspace{-.4\parskip}

Researched various deep learning models for audio signal processing using microphone array on robots.
\vspace{-.9\parskip}
\begin{itemize}[nosep]
  \item Developed deep learning-based sound source localization models for human-robot interactions.
  \item Achieved more than 90\% precision and recall for detecting and localizing multiple simultaneous sources in real-time. [\href{https://www.youtube.com/watch?v=_4EwuVlE_pU}{video demo}]
  \item Researched models for joint localization and speech/non-speech classification of multiple sound sources. Achieved 20\% relative accuracy improvement over traditional methods. [\href{https://www.youtube.com/watch?v=O7bQvg03RTc}{video demo}]
  \item Innovated data augmentation and domain adaptation methods for low-resource training of sound source localization neural networks.
\end{itemize}

%------------------------------------------------

\textbf{Facebook}  \hfill Menlo Park, CA\\
\textit{Research Intern} \hfill July 2019 --- October 2019%
\vspace{-.4\parskip}

Developed deep beamforming neural networks for far-field automatic speech recognition on smart speakers.
\vspace{-1.8\parskip}
\begin{itemize}[nosep]
  \item Reduced word error rate by 9\% by using the proposed spatial attention.
\end{itemize}

%------------------------------------------------

\textbf{6Estates}  \hfill Singapore \\
\textit{Software Engineer} \hfill January 2016 --- May 2016%
\vspace{-.4\parskip}

\begin{itemize}[nosep]
  \item Developed back-end web interface for a deep learning based information retrieval system.
\end{itemize}

%------------------------------------------------

\textbf{University of Hamburg} \hfill Germany \\
\textit{Research Assistant}  \hfill October 2012 --- November 2015%
\vspace{-.4\parskip}

\begin{itemize}[nosep]
  \item Conducted research on interactive object recognition with audio-visual sensory fusion, resulting in two peer-reviewed publications.
\end{itemize}

%------------------------------------------------

\textbf{Hulu} \hfill Beijing, China \\
\textit{Research Intern} \hfill July --- September 2012%
\vspace{-.5\parskip}

\begin{itemize}[nosep]
  \item Optimized search engine using fast approximate string matching.
\end{itemize}

%------------------------------------------------

%%%%%%%%%%%%%%%%%% DELETE %%%%%%%%%%%%%%%%%%%%%%%
\iffalse{}
%%%%%%%%%%%%%%%%%% DELETE %%%%%%%%%%%%%%%%%%%%%%%

\textbf{Tsinghua University}, Intelligent Information Acquisition Group \hfill Beijing, China \\
\textit{Research Assistant} \hfill February --- June 2012
\vspace{-\parskip}
\begin{itemize}
  \item Implemented cell phone retail dialog system incorporating reinforcement learning.
\end{itemize}

%------------------------------------------------

\textbf{Tsinghua University}, Department of Mathematical Sciences \hfill Beijing, China \\
\textit{Research Assistant} \hfill February --- June 2012
\vspace{-\parskip}
\begin{itemize}
  \item Studied Lagrangian method for wave equations.
\end{itemize}

%------------------------------------------------

\textbf{Tsinghua University}, Nature Language Processing Lab \hfill Beijing, China \\
\textit{Research Assistant} \hfill 2010 --- 2012
\vspace{-\parskip}
\begin{itemize}
  \item Explored methods for keyword extraction and word sense disambiguation using Wikipedia data.
  \item Constructed news corpus from Internet resources for keyword extraction.
\end{itemize}

%%%%%%%%%%%%%%%%%% END    %%%%%%%%%%%%%%%%%%%%%%%
\fi
%%%%%%%%%%%%%%%%%% END    %%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	SKILLS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Skills}

\begin{tabular}{rl}
  Programming: & Python $\bullet$ C $\bullet$ C++ $\bullet$ Java $\bullet$ MATLAB \\
  Libraries: & PyTorch $\bullet$ Gstreamer $\bullet$ OpenCV $\bullet$ GSL $\bullet$ OpenMP $\bullet$ OpenMPI $\bullet$ Spark \\
  Other Tools: & Vim $\bullet$ Bash $\bullet$ \LaTeX{} $\bullet$ GDB $\bullet$ Git $\bullet$ Mercurial $\bullet$ Gnuplot \\
  Languages: & English (full professional proficiency) $\bullet$ Chinese: (native) $\bullet$ German (basic) $\bullet$ French (basic) \\
\end{tabular}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	Awards
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Awards}

\begin{itemize}[itemsep=-.9em]
  \item Distinction of an outstanding thesis in electrical engineering, EPFL (top 8\%), 2021
  \item Best student paper award finalist, \textit{Interspeech}, 2018
  \item Outstanding graduate, Tsinghua University (top 10\%), 2012
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	Education
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Education}
\parbox{\textwidth}{%
\textbf{Doctor of Philosophy (Ph.D.) in \textit{Electrical Engineering}} \\
\ind{} \'Ecole Polytechnique F\'ed\'erale de Lausanne (EPFL) \hfill Switzerland
}

\parbox{\textwidth}{%
\textbf{Master of Science (M.Sc.) in \textit{Intelligent Adaptive Systems}} \\
\ind{} University of Hamburg \hfill Germany
}

\parbox{\textwidth}{%
\textbf{Bachelor of Engineering (B.E.) in \textit{Computer Science and Technology}} \\
\ind{} Tsinghua University \hfill China
}

\parbox{\textwidth}{%
\textbf{Bachelor of Science (B.S.) in \textit{Pure and Applied Mathematics}} (second major) \\
\ind{} Tsinghua University \hfill China
}

%%%%%%%%%%%%%%%%%% DELETE %%%%%%%%%%%%%%%%%%%%%%%
\iffalse{}
%%%%%%%%%%%%%%%%%% DELETE %%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	EDUCATION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Education}
\parbox{\textwidth}{%
\textbf{\'Ecole Polytechnique F\'ed\'erale de Lausanne (EPFL)} \hfill Switzerland \\
\ind{} Ph.D. in \textit{Electrical Engineering} \hfill March 2021 \\
\ind{} --- Thesis title: \textit{Deep Learning Approaches for Auditory Perception in Robotics} \\
\ind{} --- Supervisors: \href{https://idiap.ch/~odobez}{Dr. Jean-Marc Odobez} and \href{https://people.idiap.ch/pmotlic}{Dr. Petr Motlicek}
}

\parbox{\textwidth}{%
\textbf{University of Hamburg} \hfill Germany \\
\ind{} M.Sc.\ in \textit{Intelligent Adaptive Systems}, GPA\@: 1.38/1.0 (excellent)  \hfill September 2015%
%\ind - Thesis: Visual-Audio Object Recognition Using Hidden Markov Models (Grade: 1.0)
}

\parbox{\textwidth}{%
\textbf{Tsinghua University} \hfill China \\
\ind{} B.E. in \textit{Computer Science and Technology}, GPA\@: 90/100 (top 10\%) \hfill July 2012 \\
\ind{} B.S. in \textit{Pure and Applied Mathematics} (second major), GPA\@: 83/100 %\hfill July 2012
}

%------------------------------------------------
%\pagebreak
%\section*{Education (continued)}
%------------------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	PUBLICATIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Selected Publications}
\begin{enumerate}[label={[\arabic*]}]
% \item Egocentric Audio-Visual Noise Suppression. \\
%       Roshan Sharma, Weipeng He, Ju Lin, Egor Lakomkin, Yang Liu, Kaustubh Kalgaonkar, \\
%       in \textit{2023 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)}
%       [\href{https://doi.org/10.1109/ICASSP49357.2023.10095890}{doi}]

  \item Multi-task Neural Network for Robust Multiple Speaker Embedding Extraction. \\
        Weipeng He, Petr Motlicek, and Jean-Marc Odobez, \\
        in \textit{Proc. Interspeech 2021}
        [\href{https://doi.org/10.21437/Interspeech.2021-1769}{doi}]

  \item Neural Network Adaptation and Data Augmentation for Multi-Speaker Direction-of-Arrival Estimation. \\
        Weipeng He, Petr Motlicek, and Jean-Marc Odobez, \\
        \textit{IEEE/ACM Transactions on Audio, Speech, and Language Processing}, vol. 29, pp. 1303â€“1317, 2021
        [\href{https://doi.org/10.1109/TASLP.2021.3060257}{doi}]

% \item IEEE SLT 2021 Alpha-mini Speech Challenge: Open Datasets, Tracks, Rules and Baselines. \\
%       Yihui Fu, Weipeng He, et al. \\
%       in \textit{2021 IEEE Spoken Language Technology Workshop (SLT)}
%       [\href{https://doi.org/10.1109/SLT48900.2021.9383546}{doi}]

  \item Spatial attention for far-field speech recognition with deep beamforming neural networks. \\
        Weipeng He, Lu Lu, Biqiao Zhang, Jay Mahadeokar, Kaustubh Kalgaonkar, and Christian Fuegen, \\
        in \textit{2020 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)}
        [\href{https://doi.org/10.1109/ICASSP40776.2020.9053439}{doi}]

% \item The MuMMER Data Set for Robot Perception in Multi-Party HRI Scenarios. \\
%       Olivier Canevet, Weipeng He, Petr Motlicek, and Jean-Marc Odobez, \\
%       in \textit{2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)}

  \item Adaptation of multiple sound source localization neural networks with weak supervision and domain-adversarial training. \\
        Weipeng He, Petr Motlicek, and Jean-Marc Odobez, \\
        in \textit{2019 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)}
        [\href{https://doi.org/10.1109/ICASSP.2019.8682655}{doi}]

  \item MuMMER:\@ Socially intelligent human-robot interaction in public spaces. \\
        Mary Ellen Foster, Weipeng He, et al. \\
        in \textit{Proc.\ AI-HRI 2019}
        [\href{https://arxiv.org/abs/1909.06749}{preprint}]

  \item Joint localization and classification of multiple sound sources using a multi-task neural network. \\
        Weipeng He, Petr Motlicek, and Jean-Marc Odobez, \\
        in \textit{Proc. Interspeech 2018}
        [\href{http://doi.org/10.21437/Interspeech.2018-1269}{doi}, \href{https://www.youtube.com/watch?v=O7bQvg03RTc}{video}]

  \item Deep neural networks for multiple speaker detection and localization. \\
        Weipeng He, Petr Motlicek, and Jean-Marc Odobez, \\
        in \textit{2018 IEEE International Conference on Robotics and Automation (ICRA)}
        [\href{http://doi.org/10.1109/ICRA.2018.8461267}{doi}, \href{https://www.youtube.com/watch?v=_4EwuVlE_pU}{video}]

% \item Multimodal object recognition from visual and audio sequences. \\
%       Weipeng He, Haojun Guan, and Jianwei Zhang, \\
%       in \textit{2015 IEEE Int.\ Conf.\ on Multisensor Fusion and Information Integration for Intelligent Systems (MFI)}

% \item What to do first: the initial behavior in a multi-sensory household object recognition and categorization system. \\
%       Haojun Guan, Weipeng He, and Jianwei Zhang, \\
%       in \textit{2014 IEEE Int.\ Conf.\ on Multisensor Fusion and Information Integration for Intelligent Systems (MFI)}

% \item THUNLP at TAC KBP 2011 in entity linking. \\
%       Yu Zhao, Weipeng He, Zhiyuan Liu, and Maosong Sun, \\
%       in \textit{Proceedings of TAC, 2011}
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	PEER REVIEWS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Peer Reviews}

\begin{itemize}[itemsep=-.9em]
  \item \textit{IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 2021-2024
  \item \textit{IEEE Signal Processing Letters}, 2019-2024
  \item \textit{IEEE Robotics and Automation Letters}, 2021-2022
  \item \textit{Journal of Sound and Vibration (JSV)}, 2020-2021
  \item \textit{Interspeech}, 2021
  \item \textit{European Conference on Computer Vision (ECCV)}, 2020
  \item \textit{IEEE International Conference on Robotics and Automation (ICRA)}, 2020
  \item \textit{ACM International Conference on Multimodal Interaction (ICMI)}, 2018
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	Other Research Activities
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Other Research Activities}

\begin{tabular}{rl}
  Challenges: & Co-organizer of the \href{http://asc.ubtrobot.com/}{IEEE SLT 2021 Alpha-mini Speech Challenge}. \\
  Datasets:   & Creator of the \href{https://www.idiap.ch/dataset/sslr}{SSLR dataset} and \href{https://www.idiap.ch/dataset/mummer}{MuMMER dataset}. \\
\end{tabular}

%%%%%%%%%%%%%%%%%% END    %%%%%%%%%%%%%%%%%%%%%%%
\fi
%%%%%%%%%%%%%%%%%% END    %%%%%%%%%%%%%%%%%%%%%%%

\section{Research Activities}

\begin{tabular}{rl}
  Google scholar: & \href{https://scholar.google.ch/citations?user=m6VYhKMAAAAJ&hl=en}{scholar.google.ch/citations?user=m6VYhKMAAAAJ} \\
  Publications: & \href{http://hwp.github.io/publications.pdf}{hwp.github.io/publications.pdf} \\
  Peer reviews: & \href{http://hwp.github.io/reviews.pdf}{hwp.github.io/reviews.pdf} \\
\end{tabular}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	update date
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vfill
\centering \footnotesize \itshape{Updated on \today}

\end{document}

