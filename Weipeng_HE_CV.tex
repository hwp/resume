%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Plasmati Graduate CV
% LaTeX Template
% Version 1.0 (24/3/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Alessandro Plasmati (alessandro.plasmati@gmail.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
% Important note:
% This template needs to be compiled with XeLaTeX.
% The main document font is called Fontin and can be downloaded for free
% from here: http://www.exljbris.com/fontin.html
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[a4paper,9pt]{extarticle} % Default font size and paper size

\usepackage{fontspec} % For loading fonts
%\defaultfontfeatures{Mapping=tex-text}
\setmainfont{Lora}
\setsansfont{Muli}
\setmonofont{Muli}
%\setmonofont[Scale=0.9]{Roboto Mono}

\usepackage{parskip}

\usepackage[usenames,dvipsnames]{xcolor} % Required for specifying custom colors

%\usepackage{fullpage}
\usepackage[left=2cm, right=2cm, top=2cm, bottom=2cm]{geometry}

\usepackage{soul}

\usepackage[bookmarks]{hyperref}
\definecolor{linkcolour}{rgb}{0,0.2,0.6} % Link color
\hypersetup{colorlinks,breaklinks,urlcolor=linkcolour,linkcolor=linkcolour} % Set link colors throughout the document

\usepackage{titlesec} % Used to customize the \section command
\titleformat{\section}{\LARGE\bfseries\scshape\sffamily\raggedright}{}{0em}{}[\titlerule] % Text formatting of sections
\titlespacing{\section}{0pt}{8mm}{3mm} % Spacing around sections

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\rhead{Weipeng He, Page \thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\setlength{\headheight}{15pt}
\setlength{\headsep}{10pt}

\usepackage{enumitem}
\setitemize{itemsep=-.4em,leftmargin=2em}
%\renewcommand\labelitemi{-}

\hyphenation{Tsinghua}
\newcommand{\ind}{\hspace*{1em}}

\setlength{\parskip}{12pt}

\newcommand{\version}{0}

\begin{document}
\thispagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	NAME AND CONTACT INFORMATION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{center}
  {\Huge\bfseries\sffamily WEIPENG HE}

  Seattle, WA 98109 $\bullet$
  \href{mailto:heweipeng@gmail.com}{\texttt{heweipeng@gmail.com}} $\bullet$
  \texttt{+1 (206) 209-7280} $\bullet$
  \url{www.linkedin.com/in/hwp0}
%\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	Key Words
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\LARGE\bfseries\sffamily %
\ifcase\version
  Speech \& Audio
\or
  Senior
\or
  Speech \& Audio
\or
  Speech \& Audio
\else
  Senior
\fi
Research Scientist} \\[4pt]
%
\ifcase\version
% version zero nothing
\or
  Audio and Speech Processing $\bullet$ Machine Learning $\bullet$ Voice AI $\bullet$ Model Optimization \& Compression \\
  Speech Enhancement $\bullet$ Microphone Array Processing $\bullet$ Keyword Spotting $\bullet$ Sound Separation \& Localization
\or
  Audio and Speech Processing $\bullet$ Machine Learning $\bullet$ Voice AI $\bullet$ On-device Model Optimization $\bullet$ Audio DSP \\
  Speech Enhancement $\bullet$ Microphone Array Processing $\bullet$ Keyword Spotting $\bullet$ Sound Separation \& Localization
\or
  Speech and Audio Processing $\bullet$ Machine Learning $\bullet$ Voice AI $\bullet$ Speech Enhancement $\bullet$ Speech Recognition \\
  Keyword Spotting $\bullet$ Sound Separation $\bullet$ Sound Event Detection \& Localization $\bullet$ Model Optimization \& Compression
\else
  Speech and Audio Processing $\bullet$ Machine Learning $\bullet$ Voice AI $\bullet$ Speech Enhancement $\bullet$ Speech Recognition \\
  Keyword Spotting $\bullet$ Sound Separation $\bullet$ Sound Event Detection \& Localization $\bullet$ Model Optimization \& Compression
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Experiences
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Work Experience}

\textbf{Senior Research Scientist} \hfill February 2023 --- Present \\
Meta, Speech AI \hfill Seattle, WA \\
\vspace{-1.5\parskip}

Conducted research and deployment of emerging speech and audio technologies for wearable devices in challenging acoustic environments, leveraging advanced signal processing and machine learning techniques.
\vspace{-.9\parskip}
\begin{itemize}[nosep]
  \item Developed multi-channel end-to-end wake word detection models for smart glasses, reducing false rejection rate by 13\% in noisy conditions and increasing 30-minute battery life by optimization.
  \item Implemented real-time barge-in detection on smart glasses, achieving less than 5\% false rejection and false acceptance rates, enabling seamless natural conversation with large language models.
  \item Designed and prototyped an audio ``magic eraser'' model, enabling selective suppression or enhancement of specific sounds in videos.
  \item Mentored an intern on a research project focused on multi-channel sound separation leveraging spatial information from microphone arrays.
  \item Led the implementation of automated data preprocessing and augmentation pipeline for wake word detection model development, reducing manual effort by 90\%.
\end{itemize}

\textbf{Research Scientist} \hfill September 2021 --- January 2023 \\
Meta, Speech AI \hfill Seattle, WA \\
\vspace{-1.5\parskip}

Conducted research and deployment of speech enhancement technologies applied to various products at Meta.
\vspace{-.9\parskip}
\begin{itemize}[nosep]
  \item Deployed a lightweight speech enhancement model to a DSP on smart glasses, reducing computational cost by 30\% through quantization and computational graph optimization techniques.
  \item Mentored an intern research project on audio-visual noise suppression from a ego-centric perspective, leveraging multimodal fusion and multitask learning.
  \item Contributed to the noise suppression training infra and collaborated with cross-functional teams to deploy noise suppression to Messenger.
\end{itemize}

% \textit{Postdoctoral Researcher} \hfill November 2020 --- August 2021 \\
% \textit{Research Assistant} \hfill June 2016 --- October 2020%
\textbf{Research Assistant} \hfill June 2016 --- August 2021 \\
Idiap Research Institute, Perception \& Activity Understanding  \hfill Martigny, Switzerland \\
\vspace{-1.5\parskip}

Researched and developed deep learning models for audio perception on robots in challenging human-robot interaction environments.
\vspace{-.9\parskip}
\begin{itemize}[nosep]
  \item Developed deep learning-based sound source localization models for robots, achieving over 90\% precision and recall for real-time detection and localization of multiple simultaneous sounds sources. [\href{https://www.youtube.com/watch?v=_4EwuVlE_pU}{video demo}]
  \item Researched models for joint localization and speech/non-speech classification of multiple sound sources, achieving 20\% relative accuracy improvement. [\href{https://www.youtube.com/watch?v=O7bQvg03RTc}{video demo}]
  \item Innovated data augmentation and domain adaptation methods for low-resource training of sound source localization neural networks, enabling development of accurate models using weakly-labelled training data.
\end{itemize}

%------------------------------------------------

\textbf{Research Intern} \hfill July 2019 --- October 2019 \\
Facebook, Speech AI  \hfill Menlo Park, CA \\
\vspace{-1.5\parskip}

Designed and developed deep beamforming neural networks for far-field automatic speech recognition on smart speakers.
\vspace{-0.9\parskip}
\begin{itemize}[nosep]
  \item Investigated and compared various state-of-the-art neural beamformer paradigms as the front-end component of far-field automatic speech recognition systems.
  \item Innovated a spatial attention module for factorized complex linear projection models, reducing word error rate by 9\%.
\end{itemize}

%------------------------------------------------

%%%%%%%%%%%%%%%%%% DELETE %%%%%%%%%%%%%%%%%%%%%%%
\iffalse{}
%%%%%%%%%%%%%%%%%% DELETE %%%%%%%%%%%%%%%%%%%%%%%

\textbf{Software Engineer} \hfill January 2016 --- May 2016 \\
\textbf{6Estates} (\textit{Startup})  \hfill Singapore \\
\vspace{-1.5\parskip}

\begin{itemize}[nosep]
  \item Developed back-end web interface for a deep learning based information retrieval system.
\end{itemize}

%------------------------------------------------

\textbf{Research Assistant} \hfill October 2012 --- November 2015 \\
\textbf{University of Hamburg}, Technical Aspects of Multimodal Systems \hfill Germany \\
\vspace{-1.5\parskip}

\begin{itemize}[nosep]
  \item Conducted research on interactive object recognition with audio-visual sensory fusion, resulting in two peer-reviewed publications.
\end{itemize}

%------------------------------------------------

\textit{Research Intern} \hfill July --- September 2012 \\
\textbf{Hulu} \hfill Beijing, China \\
\vspace{-1.5\parskip}

\begin{itemize}[nosep]
  \item Optimized search engine using fast approximate string matching.
\end{itemize}

%------------------------------------------------

\textbf{Tsinghua University}, Intelligent Information Acquisition Group \hfill Beijing, China \\
\textit{Research Assistant} \hfill February --- June 2012
\vspace{-\parskip}
\begin{itemize}
  \item Implemented cell phone retail dialog system incorporating reinforcement learning.
\end{itemize}

%------------------------------------------------

\textbf{Tsinghua University}, Department of Mathematical Sciences \hfill Beijing, China \\
\textit{Research Assistant} \hfill February --- June 2012
\vspace{-\parskip}
\begin{itemize}
  \item Studied Lagrangian method for wave equations.
\end{itemize}

%------------------------------------------------

\textbf{Tsinghua University}, Nature Language Processing Lab \hfill Beijing, China \\
\textit{Research Assistant} \hfill 2010 --- 2012
\vspace{-\parskip}
\begin{itemize}
  \item Explored methods for keyword extraction and word sense disambiguation using Wikipedia data.
  \item Constructed news corpus from Internet resources for keyword extraction.
\end{itemize}

%%%%%%%%%%%%%%%%%% END    %%%%%%%%%%%%%%%%%%%%%%%
\fi
%%%%%%%%%%%%%%%%%% END    %%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	SKILLS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Skills}

\begin{tabular}{rl}
  Programming: & Python $\bullet$ C $\bullet$ C++ $\bullet$  MATLAB \\
  Libraries: & PyTorch $\bullet$ NumPy $\bullet$ Gstreamer $\bullet$ OpenCV $\bullet$ GSL $\bullet$ Spark \\
  Other Tools: & Vim $\bullet$ Bash $\bullet$ \LaTeX{} $\bullet$ GDB $\bullet$ Git $\bullet$ Mercurial $\bullet$ Gnuplot \\
  Languages: & English (full professional proficiency) $\bullet$ Chinese (native) $\bullet$ German (basic) $\bullet$ French (basic) \\
\end{tabular}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	Awards
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Awards}

\begin{itemize}[itemsep=-.9em]
  \item Distinction of an outstanding thesis in electrical engineering, EPFL (top 8\%), 2021
  \item Best student paper award finalist, \textit{Interspeech}, 2018
  \item Outstanding graduate, Tsinghua University (top 10\%), 2012
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	Education
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Education}
\parbox{\textwidth}{%
\textbf{Doctor of Philosophy (Ph.D.) in \textit{Electrical Engineering}} \\
\ind{} \'Ecole Polytechnique F\'ed\'erale de Lausanne (EPFL) \hfill Switzerland
}

\parbox{\textwidth}{%
\textbf{Master of Science (M.Sc.) in \textit{Intelligent Adaptive Systems}} \\
\ind{} University of Hamburg \hfill Germany
}

\parbox{\textwidth}{%
\textbf{Bachelor of Engineering (B.E.) in \textit{Computer Science and Technology}} \\
\ind{} Tsinghua University \hfill China
}

\parbox{\textwidth}{%
\textbf{Bachelor of Science (B.S.) in \textit{Pure and Applied Mathematics}} (second major) \\
\ind{} Tsinghua University \hfill China
}

%%%%%%%%%%%%%%%%%% DELETE %%%%%%%%%%%%%%%%%%%%%%%
\iffalse{}
%%%%%%%%%%%%%%%%%% DELETE %%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	EDUCATION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Education}
\parbox{\textwidth}{%
\textbf{\'Ecole Polytechnique F\'ed\'erale de Lausanne (EPFL)} \hfill Switzerland \\
\ind{} Ph.D. in \textit{Electrical Engineering} \hfill March 2021 \\
\ind{} --- Thesis title: \textit{Deep Learning Approaches for Auditory Perception in Robotics} \\
\ind{} --- Supervisors: \href{https://idiap.ch/~odobez}{Dr. Jean-Marc Odobez} and \href{https://people.idiap.ch/pmotlic}{Dr. Petr Motlicek}
}

\parbox{\textwidth}{%
\textbf{University of Hamburg} \hfill Germany \\
\ind{} M.Sc.\ in \textit{Intelligent Adaptive Systems}, GPA\@: 1.38/1.0 (excellent)  \hfill September 2015%
%\ind - Thesis: Visual-Audio Object Recognition Using Hidden Markov Models (Grade: 1.0)
}

\parbox{\textwidth}{%
\textbf{Tsinghua University} \hfill China \\
\ind{} B.E. in \textit{Computer Science and Technology}, GPA\@: 90/100 (top 10\%) \hfill July 2012 \\
\ind{} B.S. in \textit{Pure and Applied Mathematics} (second major), GPA\@: 83/100 %\hfill July 2012
}

%------------------------------------------------
%\pagebreak
%\section*{Education (continued)}
%------------------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	PUBLICATIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Selected Publications}
\begin{enumerate}[label={[\arabic*]}]
% \item Egocentric Audio-Visual Noise Suppression. \\
%       Roshan Sharma, Weipeng He, Ju Lin, Egor Lakomkin, Yang Liu, Kaustubh Kalgaonkar, \\
%       in \textit{2023 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)}
%       [\href{https://doi.org/10.1109/ICASSP49357.2023.10095890}{doi}]

  \item Multi-task Neural Network for Robust Multiple Speaker Embedding Extraction. \\
        Weipeng He, Petr Motlicek, and Jean-Marc Odobez, \\
        in \textit{Proc. Interspeech 2021}
        [\href{https://doi.org/10.21437/Interspeech.2021-1769}{doi}]

  \item Neural Network Adaptation and Data Augmentation for Multi-Speaker Direction-of-Arrival Estimation. \\
        Weipeng He, Petr Motlicek, and Jean-Marc Odobez, \\
        \textit{IEEE/ACM Transactions on Audio, Speech, and Language Processing}, vol. 29, pp. 1303â€“1317, 2021
        [\href{https://doi.org/10.1109/TASLP.2021.3060257}{doi}]

% \item IEEE SLT 2021 Alpha-mini Speech Challenge: Open Datasets, Tracks, Rules and Baselines. \\
%       Yihui Fu, Weipeng He, et al. \\
%       in \textit{2021 IEEE Spoken Language Technology Workshop (SLT)}
%       [\href{https://doi.org/10.1109/SLT48900.2021.9383546}{doi}]

  \item Spatial attention for far-field speech recognition with deep beamforming neural networks. \\
        Weipeng He, Lu Lu, Biqiao Zhang, Jay Mahadeokar, Kaustubh Kalgaonkar, and Christian Fuegen, \\
        in \textit{2020 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)}
        [\href{https://doi.org/10.1109/ICASSP40776.2020.9053439}{doi}]

% \item The MuMMER Data Set for Robot Perception in Multi-Party HRI Scenarios. \\
%       Olivier Canevet, Weipeng He, Petr Motlicek, and Jean-Marc Odobez, \\
%       in \textit{2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)}

  \item Adaptation of multiple sound source localization neural networks with weak supervision and domain-adversarial training. \\
        Weipeng He, Petr Motlicek, and Jean-Marc Odobez, \\
        in \textit{2019 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)}
        [\href{https://doi.org/10.1109/ICASSP.2019.8682655}{doi}]

  \item MuMMER:\@ Socially intelligent human-robot interaction in public spaces. \\
        Mary Ellen Foster, Weipeng He, et al. \\
        in \textit{Proc.\ AI-HRI 2019}
        [\href{https://arxiv.org/abs/1909.06749}{preprint}]

  \item Joint localization and classification of multiple sound sources using a multi-task neural network. \\
        Weipeng He, Petr Motlicek, and Jean-Marc Odobez, \\
        in \textit{Proc. Interspeech 2018}
        [\href{http://doi.org/10.21437/Interspeech.2018-1269}{doi}, \href{https://www.youtube.com/watch?v=O7bQvg03RTc}{video}]

  \item Deep neural networks for multiple speaker detection and localization. \\
        Weipeng He, Petr Motlicek, and Jean-Marc Odobez, \\
        in \textit{2018 IEEE International Conference on Robotics and Automation (ICRA)}
        [\href{http://doi.org/10.1109/ICRA.2018.8461267}{doi}, \href{https://www.youtube.com/watch?v=_4EwuVlE_pU}{video}]

% \item Multimodal object recognition from visual and audio sequences. \\
%       Weipeng He, Haojun Guan, and Jianwei Zhang, \\
%       in \textit{2015 IEEE Int.\ Conf.\ on Multisensor Fusion and Information Integration for Intelligent Systems (MFI)}

% \item What to do first: the initial behavior in a multi-sensory household object recognition and categorization system. \\
%       Haojun Guan, Weipeng He, and Jianwei Zhang, \\
%       in \textit{2014 IEEE Int.\ Conf.\ on Multisensor Fusion and Information Integration for Intelligent Systems (MFI)}

% \item THUNLP at TAC KBP 2011 in entity linking. \\
%       Yu Zhao, Weipeng He, Zhiyuan Liu, and Maosong Sun, \\
%       in \textit{Proceedings of TAC, 2011}
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	PEER REVIEWS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Peer Reviews}

\begin{itemize}[itemsep=-.9em]
  \item \textit{IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 2021-2024
  \item \textit{IEEE Signal Processing Letters}, 2019-2024
  \item \textit{IEEE Robotics and Automation Letters}, 2021-2022
  \item \textit{Journal of Sound and Vibration (JSV)}, 2020-2021
  \item \textit{Interspeech}, 2021
  \item \textit{European Conference on Computer Vision (ECCV)}, 2020
  \item \textit{IEEE International Conference on Robotics and Automation (ICRA)}, 2020
  \item \textit{ACM International Conference on Multimodal Interaction (ICMI)}, 2018
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	Other Research Activities
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Other Research Activities}

\begin{tabular}{rl}
  Challenges: & Co-organizer of the \href{http://asc.ubtrobot.com/}{IEEE SLT 2021 Alpha-mini Speech Challenge}. \\
  Datasets:   & Creator of the \href{https://www.idiap.ch/dataset/sslr}{SSLR dataset} and \href{https://www.idiap.ch/dataset/mummer}{MuMMER dataset}. \\
\end{tabular}

%%%%%%%%%%%%%%%%%% END    %%%%%%%%%%%%%%%%%%%%%%%
\fi
%%%%%%%%%%%%%%%%%% END    %%%%%%%%%%%%%%%%%%%%%%%

\section{Research Activities}

\begin{tabular}{rl}
  Google scholar: & \href{https://scholar.google.ch/citations?user=m6VYhKMAAAAJ&hl=en}{scholar.google.ch/citations?user=m6VYhKMAAAAJ} \\
  Publications: & \href{http://hwp.github.io/publications.pdf}{hwp.github.io/publications.pdf} \\
  Peer reviews: & \href{http://hwp.github.io/reviews.pdf}{hwp.github.io/reviews.pdf} \\
\end{tabular}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	update date
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vfill
\centering \footnotesize \itshape{Updated on \today}

\end{document}

