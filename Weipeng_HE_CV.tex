%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Plasmati Graduate CV
% LaTeX Template
% Version 1.0 (24/3/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Alessandro Plasmati (alessandro.plasmati@gmail.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
% Important note:
% This template needs to be compiled with XeLaTeX.
% The main document font is called Fontin and can be downloaded for free
% from here: http://www.exljbris.com/fontin.html
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[a4paper,9pt]{extarticle} % Default font size and paper size

\usepackage{fontspec} % For loading fonts
%\defaultfontfeatures{Mapping=tex-text}
\setmainfont{Lora}
\setsansfont{Muli}
\setmonofont{Muli}
%\setmonofont[Scale=0.9]{Roboto Mono}

\usepackage{parskip}

\usepackage[usenames,dvipsnames]{xcolor} % Required for specifying custom colors

\usepackage{fullpage}

\usepackage{soul}

\usepackage[bookmarks]{hyperref}
\definecolor{linkcolour}{rgb}{0,0.2,0.6} % Link color
\hypersetup{colorlinks,breaklinks,urlcolor=linkcolour,linkcolor=linkcolour} % Set link colors throughout the document

\usepackage{titlesec} % Used to customize the \section command
\titleformat{\section}{\LARGE\bfseries\scshape\sffamily\raggedright}{}{0em}{}[\titlerule] % Text formatting of sections
\titlespacing{\section}{0pt}{8mm}{3mm} % Spacing around sections

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\rhead{Weipeng He, Page \thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\setlength{\headheight}{15pt}
\setlength{\headsep}{10pt}

\usepackage{enumitem}
\setitemize{itemsep=-.4em,leftmargin=2em}
\renewcommand\labelitemi{-}

\hyphenation{Tsinghua}
\newcommand{\ind}{\hspace*{1em}}

\setlength{\parskip}{12pt}

\begin{document}
\thispagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	NAME AND CONTACT INFORMATION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
  {\Huge\bfseries\sffamily Weipeng He}

  \sffamily Facebook Inc., 1101 Dexter Ave N, Seattle, WA 98109, USA \\
  \url{https://hwp.github.io} $\cdotp$
  \href{mailto:heweipeng@gmail.com}{\texttt{heweipeng@gmail.com}} $\cdotp$
  \texttt{(+1) 206-209-7280}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	Research Interests
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Research Interests}
\begin{center}
Audio and Speech Processing $\cdotp$ Machine Learning $\cdotp$ Robot Auditory Perception
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	EDUCATION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Education}
\textbf{\'Ecole Polytechnique F\'ed\'erale de Lausanne (EPFL)} \hfill Switzerland \\
\ind{} Ph.D. in \textit{Electrical Engineering} \hfill March 2021 \\
\ind{} --- Thesis title: \textit{Deep Learning Approaches for Auditory Perception in Robotics} \\
\ind{} --- Supervisors: \href{https://idiap.ch/~odobez}{Dr. Jean-Marc Odobez} and \href{https://people.idiap.ch/pmotlic}{Dr. Petr Motlicek}

\textbf{University of Hamburg} \hfill Germany \\
\ind{} M.Sc.\ in \textit{Intelligent Adaptive Systems}, GPA\@: 1.38/1.0 (excellent)  \hfill September 2015%
%\ind - Thesis: Visual-Audio Object Recognition Using Hidden Markov Models (Grade: 1.0)

\textbf{Tsinghua University} \hfill China \\
\ind{} B.E. in \textit{Computer Science and Technology}, GPA\@: 90/100 (top 10\%) \hfill July 2012 \\
\ind{} B.S. in \textit{Pure and Applied Mathematics} (second major), GPA\@: 83/100 %\hfill July 2012

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Experiences
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Experience}

\textbf{Facebook}  \hfill USA \\
\textit{Research Scientist} \hfill September 2021 --- Present%
\vspace{-.9\parskip}
\begin{itemize}
  \item Research and deployment of machine learning techniques for audio signal processing on remote precense, augmented reality and virtual reality devices.
\end{itemize}

\textbf{Idiap Research Institute}  \hfill Switzerland \\
\textit{Postdoctoral Researcher} \hfill November 2020 --- August 2021 \\
\textit{Research Assistant} \hfill June 2016 --- Octoboer 2020%
\vspace{-.9\parskip}
\begin{itemize}
  \item Investigate deep learning-based approaches for sound source localization in real human robot interaction scenarios.
        Achieve more than 90\% precision and recall for detecting and localizing multiple simultaneous sources in real-time.
        [\href{https://www.youtube.com/watch?v=_4EwuVlE_pU}{video demo}]
  \item Investigate simultaneous localization and speech/non-speech classification of multiple sound sources.
        The joint multi-task approach significantly outperforms traditional methods those sequentially process localization and classification.
        [\href{https://www.youtube.com/watch?v=O7bQvg03RTc}{video demo}]
  \item Study data augmentation and domain adaptation for low-resource training of sound source localization neural networks.
\end{itemize}

%------------------------------------------------

\textbf{Facebook}  \hfill USA \\
\textit{Research Intern} \hfill July --- October 2019%
\vspace{-.9\parskip}
\begin{itemize}
  \item Research on deep beamforming networks for far-field automatic speech recognition.
        Propose the spatial attention that improves the recognition rate by 9\% on smart speakers.
\end{itemize}

%------------------------------------------------

\textbf{6Estates}  \hfill Singapore \\
\textit{Software Engineer} \hfill January --- May 2016%
\vspace{-.9\parskip}
\begin{itemize}
  \item Develop back-end web interface of a deep learning based business insight information retrieval system.
\end{itemize}

%------------------------------------------------

\textbf{University of Hamburg} \hfill Germany \\
\textit{Research Assistant}  \hfill October 2012 --- November 2015%
\vspace{-.9\parskip}
\begin{itemize}
  \item Research on interactive object recognition with audio-visual sensory fusion.
\end{itemize}

%------------------------------------------------
% \pagebreak
% \section*{Experience (cont.)}
%------------------------------------------------

\textbf{Hulu (Beijing)} \hfill China \\
\textit{Research Intern} \hfill July --- September 2012%
\vspace{-.9\parskip}
\begin{itemize}
  \item Optimize search engine with fast approximate string matching.
\end{itemize}

%------------------------------------------------

%%%%%%%%%%%%%%%%%% DELETE %%%%%%%%%%%%%%%%%%%%%%%
\iffalse{}
%%%%%%%%%%%%%%%%%% DELETE %%%%%%%%%%%%%%%%%%%%%%%

\textbf{Tsinghua University}, Intelligent Information Acquisition Group \hfill Beijing, China \\
\textit{Research Assistant} \hfill February --- June 2012
\vspace{-\parskip}
\begin{itemize}
  \item Implemented cell phone retail dialog system incorporating reinforcement learning.
\end{itemize}

%------------------------------------------------

\textbf{Tsinghua University}, Department of Mathematical Sciences \hfill Beijing, China \\
\textit{Research Assistant} \hfill February --- June 2012
\vspace{-\parskip}
\begin{itemize}
  \item Studied Lagrangian method for wave equations.
\end{itemize}

%------------------------------------------------

\textbf{Tsinghua University}, Nature Language Processing Lab \hfill Beijing, China \\
\textit{Research Assistant} \hfill 2010 --- 2012
\vspace{-\parskip}
\begin{itemize}
  \item Explored methods for keyword extraction and word sense disambiguation using Wikipedia data.
  \item Constructed news corpus from Internet resources for keyword extraction.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	Awards
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Scholarships and Awards}

Merit Scholarship for International Students, University of Hamburg \hfill 2013 --- 2015 \\
Outstanding Graduate, Tsinghua University (top 10\%) \hfill July 2012 \\
Tung OOCL Scholarship, Tsinghua University \hfill December 2010  \\
Zheng Geru Scholarship, Tsinghua University \hfill December 2009

%%%%%%%%%%%%%%%%%% END    %%%%%%%%%%%%%%%%%%%%%%%
\fi
%%%%%%%%%%%%%%%%%% END    %%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	PUBLICATIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Publications}
\begin{enumerate}[label={[\arabic*]}]
  \item Multi-task Neural Network for Robust Multiple Speaker Embedding Extraction. \\
        Weipeng He, Petr Motlicek, and Jean-Marc Odobez, \\
        in \textit{Proc. Interspeech 2021}

  \item Neural Network Adaptation and Data Augmentation for Multi-Speaker Direction-of-Arrival Estimation. \\
        Weipeng He, Petr Motlicek, and Jean-Marc Odobez, \\
        \textit{IEEE/ACM Transactions on Audio, Speech, and Language Processing}, vol. 29, pp. 1303â€“1317, 2021
        [\href{https://doi.org/10.1109/TASLP.2021.3060257}{doi}]

  \item IEEE SLT 2021 Alpha-mini Speech Challenge: Open Datasets, Tracks, Rules and Baselines. \\
        Yihui Fu, Weipeng He, et al. \\
        in \textit{2021 IEEE Spoken Language Technology Workshop (SLT)}
        [\href{https://doi.org/10.1109/SLT48900.2021.9383546}{doi}]

  \item Spatial attention for far-field speech recognition with deep beamforming neural networks. \\
        Weipeng He, Lu Lu, Biqiao Zhang, Jay Mahadeokar, Kaustubh Kalgaonkar, and Christian Fuegen, \\
        in \textit{2020 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)}
        [\href{https://doi.org/10.1109/ICASSP40776.2020.9053439}{doi}]

  \item The MuMMER Data Set for Robot Perception in Multi-Party HRI Scenarios. \\
        Olivier Canevet, Weipeng He, Petr Motlicek, and Jean-Marc Odobez, \\
        in \textit{2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)}

  \item Adaptation of multiple sound source localization neural networks with weak supervision and domain-adversarial training. \\
        Weipeng He, Petr Motlicek, and Jean-Marc Odobez, \\
        in \textit{2019 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)}
        [\href{https://doi.org/10.1109/ICASSP.2019.8682655}{doi}]

  \item MuMMER:\@ Socially intelligent human-robot interaction in public spaces. \\
        Mary Ellen Foster, Weipeng He, et al. \\
        in \textit{Proc.\ AI-HRI 2019}
        [\href{https://arxiv.org/abs/1909.06749}{preprint}]

  \item Joint localization and classification of multiple sound sources using a multi-task neural network. \\
        Weipeng He, Petr Motlicek, and Jean-Marc Odobez, \\
        in \textit{Proc. Interspeech 2018}
        [\href{http://doi.org/10.21437/Interspeech.2018-1269}{doi}, \href{https://www.youtube.com/watch?v=O7bQvg03RTc}{video}]

  \item Deep neural networks for multiple speaker detection and localization. \\
        Weipeng He, Petr Motlicek, and Jean-Marc Odobez, \\
        in \textit{2018 IEEE International Conference on Robotics and Automation (ICRA)}
        [\href{http://doi.org/10.1109/ICRA.2018.8461267}{doi}, \href{https://www.youtube.com/watch?v=_4EwuVlE_pU}{video}]

  \item Multimodal object recognition from visual and audio sequences. \\
        Weipeng He, Haojun Guan, and Jianwei Zhang, \\
        in \textit{2015 IEEE Int.\ Conf.\ on Multisensor Fusion and Information Integration for Intelligent Systems (MFI)}

  \item What to do first: the initial behavior in a multi-sensory household object recognition and categorization system. \\
        Haojun Guan, Weipeng He, and Jianwei Zhang, \\
        in \textit{2014 IEEE Int.\ Conf.\ on Multisensor Fusion and Information Integration for Intelligent Systems (MFI)}

  \item THUNLP at TAC KBP 2011 in entity linking. \\
        Yu Zhao, Weipeng He, Zhiyuan Liu, and Maosong Sun, \\
        in \textit{Proceedings of TAC, 2011}
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	Awards
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Awards}

\begin{itemize}[itemsep=-.9em]
  \item Distinction of an outstanding thesis in electrical engineering, EPFL (top 8\%), 2021
  \item Best student paper award finalist, \textit{Interspeech}, 2018
  \item Outstanding graduate, Tsinghua University (top 10\%), 2012
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	PEER REVIEWS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Peer Reviews}

\begin{itemize}[itemsep=-.9em]
  \item \textit{IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 2021-2022
  \item \textit{IEEE Robotics and Automation Letters}, 2021
  \item \textit{Interspeech}, 2021
  \item \textit{Journal of Sound and Vibration (JSV)}, 2020-2021
  \item \textit{European Conference on Computer Vision (ECCV)}, 2020
  \item \textit{IEEE International Conference on Robotics and Automation (ICRA)}, 2020
  \item \textit{IEEE Signal Processing Letters}, 2019
  \item \textit{ACM International Conference on Multimodal Interaction (ICMI)}, 2018
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	Other Research Activities
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Other Research Activities}

\begin{tabular}{rl}
  Challenges: & Co-organizer of the \href{http://asc.ubtrobot.com/}{IEEE SLT 2021 Alpha-mini Speech Challenge}. \\
  Datasets:   & Creator of the \href{https://www.idiap.ch/dataset/sslr}{SSLR dataset} and \href{https://www.idiap.ch/dataset/mummer}{MuMMER dataset}. \\
\end{tabular}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	TECHNICAL SKILLS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Technical Skills}

\begin{tabular}{rl}
  Programming: & Python $\cdotp$ C $\cdotp$ C++ $\cdotp$ Java $\cdotp$ MATLAB \\
  Libraries: & PyTorch $\cdotp$ Gstreamer $\cdotp$ OpenCV $\cdotp$ GSL $\cdotp$ OpenMP $\cdotp$ OpenMPI $\cdotp$ Spark \\
  Other Tools: & Vim $\cdotp$ Bash $\cdotp$ \LaTeX{} $\cdotp$ GDB $\cdotp$ Git $\cdotp$ Mercurial $\cdotp$ Gnuplot \\
\end{tabular}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	LANGUAGES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Languages}

\begin{tabular}{rl}
  English: & Fluent \\
  Chinese: & Native Speaker \\
  German: & Basic \\
  French: & Basic \\
\end{tabular}

\section{Miscellaneous}

\begin{tabular}{rl}
  Google scholar: & \href{https://scholar.google.ch/citations?user=m6VYhKMAAAAJ&hl=en}{scholar.google.ch/citations?user=m6VYhKMAAAAJ} \\
  GitHub: & \href{https://github.com/hwp}{github.com/hwp} (highlight projects: \href{https://github.com/hwp/apkit}{apkit}, \href{https://github.com/hwp/notGHMM}{notGHMM}) \\
\end{tabular}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	update date
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vfill
\centering \footnotesize \itshape{Updated on \today}

\end{document}

